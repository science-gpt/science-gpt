_target_: orchestrator.config.SystemConfig
model_name: gpt-3.5

model_params:
  seed: 42
  temperature: 0.0
  top_p: 0.2
  max_tokens: 512
  num_ctx: 2500

supported_models:
  - "llama3:latest"
  - "GPT-4.0"
  - "GPT-3.5"
  # - "llama3.1:8b"
  # - "phi3.5:3.8b"
  # - "mistral-nemo:12b"
  # - "gemma2:27b"
  # - "openbiollm-llama-3:8b-q6_k"
  # - "openbiollm-llama-3:8b_q8_0"
  # - "llama3.2:3B-instruct-fp16"
  # - "deepseek-v2:16b"
  # - "dolphin-llama3:8b"
  # - "llava:34b-v1.6-q5_K_M"
  # - "mistral-nemo:12b-instruct-2407-q3_K_M"
  # - "llama3.2:3b-instruct-q4_K_M"
  # - "llama3.1:8b-instruct-q4_K_M"
  # - "Mistral-7B-Instruct-v0.3-Q4_K_M:latest"
        
model_auth:
  macbook_endpoint:
  url: 
  api_key: 
  version: 

extraction:
  pdf_extract_method: "pypdf2"

chunking:
  method: "recursive_character"

embedding:
  model: "mxbai-embed-large"

vector_db:
  type: "local-chromadb"
  local_path: "chroma"
  instance_name: "chromadb-instance"
  search_strategy: "similarity"

rag_params:
  top_k_retrieval: 5
